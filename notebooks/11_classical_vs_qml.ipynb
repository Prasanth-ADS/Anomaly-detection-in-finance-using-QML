{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 11: Classical vs QML Comparison\n",
                "\n",
                "**Purpose**: Compare classical ML models with quantum ML models.\n",
                "\n",
                "**Inputs**:\n",
                "- `classical_metrics.csv`\n",
                "- `qml_metrics.csv`\n",
                "\n",
                "**Outputs**:\n",
                "- Comparison visualizations → `figures/`\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Paths\n",
                "BASE_DIR = Path('.').resolve().parent\n",
                "RESULTS_DIR = BASE_DIR / 'results'\n",
                "FIGURES_DIR = BASE_DIR / 'figures'\n",
                "\n",
                "# Style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "colors = {'classical': '#3498db', 'qml': '#9b59b6'}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load metrics\n",
                "classical_df = pd.read_csv(RESULTS_DIR / 'classical_metrics.csv')\n",
                "qml_df = pd.read_csv(RESULTS_DIR / 'qml_metrics.csv')\n",
                "\n",
                "classical_df['category'] = 'Classical'\n",
                "qml_df['category'] = 'QML'\n",
                "\n",
                "combined_df = pd.concat([classical_df, qml_df], ignore_index=True)\n",
                "\n",
                "print(f\"Classical models: {len(classical_df)}\")\n",
                "print(f\"QML models: {len(qml_df)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display results\n",
                "print(\"\\nClassical Models:\")\n",
                "print(classical_df[['model', 'f1_score', 'roc_auc', 'train_time']].to_string(index=False))\n",
                "print(\"\\nQML Models:\")\n",
                "print(qml_df[['model', 'f1_score', 'roc_auc', 'train_time', 'n_qubits']].to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Accuracy vs Runtime Trade-offs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Performance comparison\n",
                "metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, metric in enumerate(metrics):\n",
                "    ax = axes[i]\n",
                "    data = combined_df.sort_values(metric, ascending=True)\n",
                "    colors_list = [colors['classical'] if c == 'Classical' else colors['qml'] \n",
                "                   for c in data['category']]\n",
                "    \n",
                "    ax.barh(data['model'], data[metric], color=colors_list)\n",
                "    ax.set_xlabel(metric.replace('_', ' ').title())\n",
                "    ax.set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
                "    ax.set_xlim([0, 1])\n",
                "\n",
                "from matplotlib.patches import Patch\n",
                "legend_elements = [Patch(facecolor=colors['classical'], label='Classical'),\n",
                "                   Patch(facecolor=colors['qml'], label='QML')]\n",
                "axes[-1].legend(handles=legend_elements, loc='center')\n",
                "axes[-1].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'classical_vs_qml_metrics.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Efficiency scatter plot\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "for category, color in colors.items():\n",
                "    data = classical_df if category == 'classical' else qml_df\n",
                "    \n",
                "    ax.scatter(data['train_time'], data['f1_score'], \n",
                "               c=color, label=category.upper(), s=150, alpha=0.7, edgecolors='black')\n",
                "    \n",
                "    for _, row in data.iterrows():\n",
                "        ax.annotate(row['model'], (row['train_time'], row['f1_score']),\n",
                "                   fontsize=8, ha='left', va='bottom')\n",
                "\n",
                "ax.set_xlabel('Training Time (seconds)', fontsize=12)\n",
                "ax.set_ylabel('F1 Score', fontsize=12)\n",
                "ax.set_title('Accuracy vs Runtime Trade-off: Classical vs QML', fontsize=14)\n",
                "ax.legend(fontsize=10)\n",
                "ax.set_xscale('log')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'classical_vs_qml_tradeoff.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Efficiency score: F1 / log(train_time + 1)\n",
                "combined_df['efficiency'] = combined_df['f1_score'] / np.log1p(combined_df['train_time'])\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "data = combined_df.sort_values('efficiency', ascending=True)\n",
                "colors_list = [colors['classical'] if c == 'Classical' else colors['qml'] \n",
                "               for c in data['category']]\n",
                "\n",
                "ax.barh(data['model'], data['efficiency'], color=colors_list)\n",
                "ax.set_xlabel('Efficiency Score (F1 / log(time))')\n",
                "ax.set_title('Model Efficiency: Classical vs QML')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'classical_vs_qml_efficiency.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"CLASSICAL VS QML SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for metric in ['f1_score', 'roc_auc', 'train_time']:\n",
                "    classical_mean = classical_df[metric].mean()\n",
                "    qml_mean = qml_df[metric].mean()\n",
                "    \n",
                "    print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
                "    print(f\"  Classical: {classical_mean:.4f}\")\n",
                "    print(f\"  QML: {qml_mean:.4f}\")\n",
                "    \n",
                "    if metric != 'train_time':\n",
                "        winner = 'Classical' if classical_mean > qml_mean else 'QML'\n",
                "    else:\n",
                "        winner = 'Classical' if classical_mean < qml_mean else 'QML'\n",
                "    print(f\"  Winner: {winner}\")\n",
                "\n",
                "print(\"\\n\" + \"-\"*60)\n",
                "print(\"KEY INSIGHT: Classical models are typically faster and competitive\")\n",
                "print(\"on small datasets. QML shows potential but requires more qubits\")\n",
                "print(\"and circuit depth for complex patterns.\")\n",
                "print(\"\\n✅ Notebook 11 Complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}