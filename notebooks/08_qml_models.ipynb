{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 8: Quantum Machine Learning (QML) Models\n",
                "\n",
                "**Purpose**: Train and evaluate QML models with proper epoch configuration.\n",
                "\n",
                "**Epoch Config (per Master Prompt)**:\n",
                "- All QML models: `max_epochs=30-50`, `patience=5`\n",
                "- Prefer early convergence to avoid barren plateaus\n",
                "\n",
                "**Models**:\n",
                "1. VQC (max=30, patience=5)\n",
                "2. Hybrid QNN (max=30, patience=5)\n",
                "3. QSVM (kernel-based, no epochs)\n",
                "4. Quantum Autoencoder (max=30, patience=5)\n",
                "5. QGAN (max=30, patience=5)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "import time\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import pennylane as qml\n",
                "from pennylane import numpy as pnp\n",
                "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, roc_curve, confusion_matrix\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "RANDOM_SEED = 42\n",
                "np.random.seed(RANDOM_SEED)\n",
                "pnp.random.seed(RANDOM_SEED)\n",
                "torch.manual_seed(RANDOM_SEED)\n",
                "\n",
                "BASE_DIR = Path('.').resolve().parent\n",
                "FEATURES_DIR = BASE_DIR / 'data' / 'features'\n",
                "RESULTS_DIR = BASE_DIR / 'results'\n",
                "MODELS_DIR = BASE_DIR / 'models'\n",
                "FIGURES_DIR = BASE_DIR / 'figures'\n",
                "\n",
                "TARGET_COLUMN = 'Class'\n",
                "\n",
                "print(f\"PennyLane version: {qml.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Epoch Configuration (per Master Prompt)\n",
                "EPOCH_CONFIG = {\n",
                "    'VQC': {'max_epochs': 30, 'patience': 5, 'expected': '10-20'},\n",
                "    'Hybrid_QNN': {'max_epochs': 30, 'patience': 5, 'expected': '10-20'},\n",
                "    'Quantum_Autoencoder': {'max_epochs': 30, 'patience': 5, 'expected': '10-20'},\n",
                "    'QGAN': {'max_epochs': 30, 'patience': 5, 'expected': '10-20'},\n",
                "    'QSVM': {'max_epochs': None, 'patience': None, 'expected': 'N/A (kernel)'}\n",
                "}\n",
                "\n",
                "def safe_normalize(arr):\n",
                "    arr = np.asarray(arr, dtype=float)\n",
                "    min_val, max_val = arr.min(), arr.max()\n",
                "    if max_val - min_val < 1e-10:\n",
                "        return np.full_like(arr, 0.5)\n",
                "    return (arr - min_val) / (max_val - min_val)\n",
                "\n",
                "class EarlyStoppingQML:\n",
                "    \"\"\"Simple early stopping for QML (no model weights to save).\"\"\"\n",
                "    def __init__(self, patience=5):\n",
                "        self.patience = patience\n",
                "        self.counter = 0\n",
                "        self.best_loss = None\n",
                "        self.early_stop = False\n",
                "        self.stopped_epoch = 0\n",
                "    \n",
                "    def __call__(self, loss, epoch):\n",
                "        if self.best_loss is None or loss < self.best_loss * 0.999:\n",
                "            self.best_loss = loss\n",
                "            self.counter = 0\n",
                "        else:\n",
                "            self.counter += 1\n",
                "            if self.counter >= self.patience:\n",
                "                self.early_stop = True\n",
                "                self.stopped_epoch = epoch\n",
                "        return self.early_stop\n",
                "\n",
                "print(\"QML Epoch Configuration:\")\n",
                "for model, cfg in EPOCH_CONFIG.items():\n",
                "    print(f\"  {model}: max={cfg['max_epochs']}, patience={cfg['patience']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.read_csv(FEATURES_DIR / 'pca_train.csv')\n",
                "test_df = pd.read_csv(FEATURES_DIR / 'pca_test.csv')\n",
                "\n",
                "X_train_full = train_df.drop(columns=[TARGET_COLUMN]).values.astype(np.float64)\n",
                "y_train_full = train_df[TARGET_COLUMN].values.astype(np.int32)\n",
                "\n",
                "X_test_full = test_df.drop(columns=[TARGET_COLUMN]).values.astype(np.float64)\n",
                "y_test = test_df[TARGET_COLUMN].values.astype(np.int32)\n",
                "\n",
                "print(f\"Training: {X_train_full.shape}, Test: {X_test_full.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "N_QUBITS = 4\n",
                "N_SHOTS = 1024\n",
                "\n",
                "# Select first N_QUBITS features\n",
                "X_train = X_train_full[:, :N_QUBITS]\n",
                "X_test = X_test_full[:, :N_QUBITS]\n",
                "\n",
                "# Scale to [0, 2π] for angle encoding\n",
                "X_train_scaled = (X_train - X_train.min()) / (X_train.max() - X_train.min() + 1e-8) * 2 * np.pi\n",
                "X_test_scaled = (X_test - X_test.min()) / (X_test.max() - X_test.min() + 1e-8) * 2 * np.pi\n",
                "\n",
                "print(f\"QML features: {N_QUBITS}, Qubits: {N_QUBITS}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subsample for QML (computationally expensive)\n",
                "MAX_TRAIN = 200\n",
                "MAX_TEST = 100\n",
                "\n",
                "if len(X_train_full) > MAX_TRAIN:\n",
                "    X_train_qml, X_val_qml, y_train_qml, y_val_qml = train_test_split(\n",
                "        X_train_scaled, y_train_full, train_size=int(MAX_TRAIN*0.8), test_size=int(MAX_TRAIN*0.2),\n",
                "        stratify=y_train_full, random_state=RANDOM_SEED\n",
                "    )\n",
                "else:\n",
                "    X_train_qml, X_val_qml, y_train_qml, y_val_qml = train_test_split(\n",
                "        X_train_scaled, y_train_full, test_size=0.2, stratify=y_train_full, random_state=RANDOM_SEED\n",
                "    )\n",
                "\n",
                "if len(X_test_full) > MAX_TEST:\n",
                "    X_test_qml, _, y_test_qml, _ = train_test_split(\n",
                "        X_test_scaled, y_test, train_size=MAX_TEST, stratify=y_test, random_state=RANDOM_SEED\n",
                "    )\n",
                "else:\n",
                "    X_test_qml, y_test_qml = X_test_scaled, y_test\n",
                "\n",
                "print(f\"QML Train: {len(X_train_qml)}, Val: {len(X_val_qml)}, Test: {len(X_test_qml)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dev = qml.device('default.qubit', wires=N_QUBITS)\n",
                "print(f\"Device: {dev.name}\")\n",
                "\n",
                "def compute_metrics(y_true, y_pred, y_prob=None):\n",
                "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
                "    metrics = {\n",
                "        'accuracy': accuracy_score(y_true, y_pred),\n",
                "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
                "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
                "        'f1_score': f1_score(y_true, y_pred, zero_division=0),\n",
                "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
                "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
                "    }\n",
                "    if y_prob is not None and not np.any(np.isnan(y_prob)):\n",
                "        try:\n",
                "            metrics['roc_auc'] = roc_auc_score(y_true, y_prob)\n",
                "        except:\n",
                "            metrics['roc_auc'] = 0.5\n",
                "    else:\n",
                "        metrics['roc_auc'] = 0.5\n",
                "    return metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_metrics = []\n",
                "all_histories = {}\n",
                "all_probabilities = {}\n",
                "epoch_metadata = {}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. VQC with Early Stopping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training VQC...\")\n",
                "cfg = EPOCH_CONFIG['VQC']\n",
                "n_layers = 2\n",
                "\n",
                "@qml.qnode(dev)\n",
                "def vqc_circuit(weights, x):\n",
                "    AngleEmbedding(x, wires=range(N_QUBITS))\n",
                "    StronglyEntanglingLayers(weights, wires=range(N_QUBITS))\n",
                "    return qml.expval(qml.PauliZ(0))\n",
                "\n",
                "weight_shape = StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=N_QUBITS)\n",
                "weights_vqc = pnp.random.randn(*weight_shape, requires_grad=True) * 0.1\n",
                "\n",
                "def vqc_cost(weights, X, y):\n",
                "    predictions = pnp.array([vqc_circuit(weights, x) for x in X])\n",
                "    predictions = (predictions + 1) / 2  # Map to [0,1]\n",
                "    return pnp.mean((predictions - y) ** 2)\n",
                "\n",
                "opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
                "early_stop = EarlyStoppingQML(patience=cfg['patience'])\n",
                "\n",
                "train_losses, val_losses = [], []\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(cfg['max_epochs']):\n",
                "    weights_vqc, cost = opt.step_and_cost(lambda w: vqc_cost(w, X_train_qml, y_train_qml), weights_vqc)\n",
                "    train_losses.append(float(cost))\n",
                "    \n",
                "    # Validation\n",
                "    val_cost = float(vqc_cost(weights_vqc, X_val_qml, y_val_qml))\n",
                "    val_losses.append(val_cost)\n",
                "    \n",
                "    if (epoch + 1) % 10 == 0:\n",
                "        print(f\"  Epoch {epoch+1}/{cfg['max_epochs']}, Train: {cost:.4f}, Val: {val_cost:.4f}\")\n",
                "    \n",
                "    if early_stop(val_cost, epoch + 1):\n",
                "        print(f\"  Early stopping at epoch {epoch+1}\")\n",
                "        break\n",
                "\n",
                "train_time = time.time() - start_time\n",
                "stopped_epoch = early_stop.stopped_epoch if early_stop.early_stop else epoch + 1\n",
                "\n",
                "# Evaluate\n",
                "y_prob_vqc = np.array([(float(vqc_circuit(weights_vqc, x)) + 1) / 2 for x in X_test_qml])\n",
                "y_pred_vqc = (y_prob_vqc > 0.5).astype(int)\n",
                "\n",
                "metrics = compute_metrics(y_test_qml, y_pred_vqc, y_prob_vqc)\n",
                "metrics.update({'model': 'VQC', 'n_qubits': N_QUBITS, 'circuit_depth': n_layers,\n",
                "                'train_time': train_time, 'stopped_epoch': stopped_epoch})\n",
                "all_metrics.append(metrics)\n",
                "all_histories['VQC'] = {'train': train_losses, 'val': val_losses}\n",
                "all_probabilities['VQC'] = y_prob_vqc\n",
                "epoch_metadata['VQC'] = {'max_epochs': cfg['max_epochs'], 'patience': cfg['patience'], 'stopped_epoch': stopped_epoch}\n",
                "print(f\"  F1: {metrics['f1_score']:.4f}, Stopped: {stopped_epoch}/{cfg['max_epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hybrid QNN with Early Stopping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining Hybrid QNN...\")\n",
                "cfg = EPOCH_CONFIG['Hybrid_QNN']\n",
                "\n",
                "@qml.qnode(dev, interface='torch')\n",
                "def hybrid_qnn_circuit(inputs, weights):\n",
                "    AngleEmbedding(inputs, wires=range(N_QUBITS))\n",
                "    StronglyEntanglingLayers(weights, wires=range(N_QUBITS))\n",
                "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
                "\n",
                "class HybridQNN(nn.Module):\n",
                "    def __init__(self, n_qubits, n_layers=2):\n",
                "        super().__init__()\n",
                "        weight_shape = StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=n_qubits)\n",
                "        self.q_weights = nn.Parameter(torch.randn(*weight_shape) * 0.1)\n",
                "        self.post_net = nn.Sequential(\n",
                "            nn.Linear(n_qubits, 8), nn.ReLU(), nn.Linear(8, 1), nn.Sigmoid()\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        q_out = hybrid_qnn_circuit(x, self.q_weights)\n",
                "        q_out = torch.stack(q_out, dim=-1).float()  # Convert Double to Float\n",
                "        return self.post_net(q_out)\n",
                "\n",
                "model = HybridQNN(N_QUBITS)\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
                "criterion = nn.BCELoss()\n",
                "\n",
                "X_train_t = torch.tensor(X_train_qml, dtype=torch.float32)\n",
                "y_train_t = torch.tensor(y_train_qml, dtype=torch.float32)\n",
                "X_val_t = torch.tensor(X_val_qml, dtype=torch.float32)\n",
                "y_val_t = torch.tensor(y_val_qml, dtype=torch.float32)\n",
                "\n",
                "early_stop = EarlyStoppingQML(patience=cfg['patience'])\n",
                "train_losses, val_losses = [], []\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(cfg['max_epochs']):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for i in range(len(X_train_t)):\n",
                "        optimizer.zero_grad()\n",
                "        output = model(X_train_t[i]).squeeze()\n",
                "        loss = criterion(output, y_train_t[i])\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    train_losses.append(epoch_loss / len(X_train_t))\n",
                "    \n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        val_loss = sum(criterion(model(X_val_t[i]).squeeze(), y_val_t[i]).item() for i in range(len(X_val_t)))\n",
                "    val_losses.append(val_loss / len(X_val_t))\n",
                "    \n",
                "    if (epoch + 1) % 10 == 0:\n",
                "        print(f\"  Epoch {epoch+1}/{cfg['max_epochs']}, Train: {train_losses[-1]:.4f}, Val: {val_losses[-1]:.4f}\")\n",
                "    \n",
                "    if early_stop(val_losses[-1], epoch + 1):\n",
                "        print(f\"  Early stopping at epoch {epoch+1}\")\n",
                "        break\n",
                "\n",
                "train_time = time.time() - start_time\n",
                "stopped_epoch = early_stop.stopped_epoch if early_stop.early_stop else epoch + 1\n",
                "\n",
                "model.eval()\n",
                "X_test_t = torch.tensor(X_test_qml, dtype=torch.float32)\n",
                "with torch.no_grad():\n",
                "    y_prob_hqnn = np.array([model(x).item() for x in X_test_t])\n",
                "y_pred_hqnn = (y_prob_hqnn > 0.5).astype(int)\n",
                "\n",
                "metrics = compute_metrics(y_test_qml, y_pred_hqnn, y_prob_hqnn)\n",
                "metrics.update({'model': 'Hybrid_QNN', 'n_qubits': N_QUBITS, 'circuit_depth': 2,\n",
                "                'train_time': train_time, 'stopped_epoch': stopped_epoch})\n",
                "all_metrics.append(metrics)\n",
                "all_histories['Hybrid_QNN'] = {'train': train_losses, 'val': val_losses}\n",
                "all_probabilities['Hybrid_QNN'] = y_prob_hqnn\n",
                "epoch_metadata['Hybrid_QNN'] = {'max_epochs': cfg['max_epochs'], 'patience': cfg['patience'], 'stopped_epoch': stopped_epoch}\n",
                "print(f\"  F1: {metrics['f1_score']:.4f}, Stopped: {stopped_epoch}/{cfg['max_epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. QSVM (Kernel-based)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining QSVM (kernel-based)...\")\n",
                "\n",
                "@qml.qnode(dev)\n",
                "def quantum_kernel_circuit(x1, x2):\n",
                "    AngleEmbedding(x1, wires=range(N_QUBITS))\n",
                "    qml.adjoint(AngleEmbedding)(x2, wires=range(N_QUBITS))\n",
                "    return qml.probs(wires=range(N_QUBITS))\n",
                "\n",
                "def quantum_kernel(x1, x2):\n",
                "    return float(quantum_kernel_circuit(x1, x2)[0])\n",
                "\n",
                "# Smaller subset for QSVM\n",
                "n_train_qsvm = min(50, len(X_train_qml))\n",
                "n_test_qsvm = min(50, len(X_test_qml))\n",
                "\n",
                "X_train_qsvm = X_train_qml[:n_train_qsvm]\n",
                "y_train_qsvm = y_train_qml[:n_train_qsvm]\n",
                "X_test_qsvm = X_test_qml[:n_test_qsvm]\n",
                "y_test_qsvm = y_test_qml[:n_test_qsvm]\n",
                "\n",
                "start_time = time.time()\n",
                "K_train = np.zeros((n_train_qsvm, n_train_qsvm))\n",
                "for i in range(n_train_qsvm):\n",
                "    for j in range(i, n_train_qsvm):\n",
                "        K_train[i, j] = K_train[j, i] = quantum_kernel(X_train_qsvm[i], X_train_qsvm[j])\n",
                "    if (i + 1) % 10 == 0:\n",
                "        print(f\"  Kernel: {i+1}/{n_train_qsvm}\")\n",
                "\n",
                "K_test = np.zeros((n_test_qsvm, n_train_qsvm))\n",
                "for i in range(n_test_qsvm):\n",
                "    for j in range(n_train_qsvm):\n",
                "        K_test[i, j] = quantum_kernel(X_test_qsvm[i], X_train_qsvm[j])\n",
                "kernel_time = time.time() - start_time\n",
                "\n",
                "qsvm = SVC(kernel='precomputed', probability=True, random_state=RANDOM_SEED)\n",
                "qsvm.fit(K_train, y_train_qsvm)\n",
                "train_time = time.time() - start_time\n",
                "\n",
                "y_pred_qsvm = qsvm.predict(K_test)\n",
                "y_prob_qsvm = qsvm.predict_proba(K_test)[:, 1]\n",
                "\n",
                "metrics = compute_metrics(y_test_qsvm, y_pred_qsvm, y_prob_qsvm)\n",
                "metrics.update({'model': 'QSVM', 'n_qubits': N_QUBITS, 'circuit_depth': 1,\n",
                "                'train_time': train_time, 'stopped_epoch': None})\n",
                "all_metrics.append(metrics)\n",
                "all_probabilities['QSVM'] = y_prob_qsvm\n",
                "epoch_metadata['QSVM'] = {'max_epochs': None, 'patience': None, 'stopped_epoch': None}\n",
                "print(f\"  F1: {metrics['f1_score']:.4f} (kernel-based, no epochs)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Quantum Autoencoder with Early Stopping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining Quantum Autoencoder...\")\n",
                "cfg = EPOCH_CONFIG['Quantum_Autoencoder']\n",
                "\n",
                "n_latent = 2\n",
                "n_trash = N_QUBITS - n_latent\n",
                "\n",
                "@qml.qnode(dev)\n",
                "def qae_circuit(weights, x):\n",
                "    AngleEmbedding(x, wires=range(N_QUBITS))\n",
                "    for i in range(N_QUBITS):\n",
                "        qml.RY(weights[0, i], wires=i)\n",
                "        qml.RZ(weights[1, i], wires=i)\n",
                "    for i in range(N_QUBITS - 1):\n",
                "        qml.CNOT(wires=[i, i+1])\n",
                "    return [qml.expval(qml.PauliZ(i)) for i in range(n_trash)]\n",
                "\n",
                "# Train on normal samples only\n",
                "X_train_normal = X_train_qml[y_train_qml == 0][:50]\n",
                "X_val_normal = X_val_qml[y_val_qml == 0][:20]\n",
                "\n",
                "weights_qae = pnp.random.randn(2, N_QUBITS, requires_grad=True) * 0.1\n",
                "opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
                "early_stop = EarlyStoppingQML(patience=cfg['patience'])\n",
                "\n",
                "def qae_cost(weights, X):\n",
                "    total = 0.0\n",
                "    for x in X:\n",
                "        trash_exp = qae_circuit(weights, x)\n",
                "        total += sum((1 - e) ** 2 for e in trash_exp)\n",
                "    return total / len(X)\n",
                "\n",
                "train_losses, val_losses = [], []\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(cfg['max_epochs']):\n",
                "    weights_qae, cost = opt.step_and_cost(lambda w: qae_cost(w, X_train_normal), weights_qae)\n",
                "    train_losses.append(float(cost))\n",
                "    \n",
                "    val_cost = float(qae_cost(weights_qae, X_val_normal)) if len(X_val_normal) > 0 else cost\n",
                "    val_losses.append(val_cost)\n",
                "    \n",
                "    if (epoch + 1) % 10 == 0:\n",
                "        print(f\"  Epoch {epoch+1}/{cfg['max_epochs']}, Train: {cost:.4f}, Val: {val_cost:.4f}\")\n",
                "    \n",
                "    if early_stop(val_cost, epoch + 1):\n",
                "        print(f\"  Early stopping at epoch {epoch+1}\")\n",
                "        break\n",
                "\n",
                "train_time = time.time() - start_time\n",
                "stopped_epoch = early_stop.stopped_epoch if early_stop.early_stop else epoch + 1\n",
                "\n",
                "# Compute threshold and evaluate\n",
                "train_errors = [float(sum((1 - e) ** 2 for e in qae_circuit(weights_qae, x))) for x in X_train_normal]\n",
                "threshold = np.percentile(train_errors, 95)\n",
                "test_errors = np.array([float(sum((1 - e) ** 2 for e in qae_circuit(weights_qae, x))) for x in X_test_qml])\n",
                "y_pred_qae = (test_errors > threshold).astype(int)\n",
                "y_prob_qae = safe_normalize(test_errors)\n",
                "\n",
                "metrics = compute_metrics(y_test_qml, y_pred_qae, y_prob_qae)\n",
                "metrics.update({'model': 'Quantum_Autoencoder', 'n_qubits': N_QUBITS, 'circuit_depth': 2,\n",
                "                'train_time': train_time, 'stopped_epoch': stopped_epoch})\n",
                "all_metrics.append(metrics)\n",
                "all_histories['Quantum_Autoencoder'] = {'train': train_losses, 'val': val_losses}\n",
                "all_probabilities['Quantum_Autoencoder'] = y_prob_qae\n",
                "epoch_metadata['Quantum_Autoencoder'] = {'max_epochs': cfg['max_epochs'], 'patience': cfg['patience'], 'stopped_epoch': stopped_epoch}\n",
                "print(f\"  F1: {metrics['f1_score']:.4f}, Stopped: {stopped_epoch}/{cfg['max_epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. QGAN with Early Stopping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining QGAN...\")\n",
                "cfg = EPOCH_CONFIG['QGAN']\n",
                "\n",
                "n_qubits_gan = 2\n",
                "dev_gan = qml.device('default.qubit', wires=n_qubits_gan)\n",
                "\n",
                "@qml.qnode(dev_gan)\n",
                "def qgan_discriminator(weights, x):\n",
                "    qml.RY(x[0], wires=0)\n",
                "    qml.RY(x[1], wires=1)\n",
                "    qml.RY(weights[0], wires=0)\n",
                "    qml.RY(weights[1], wires=1)\n",
                "    qml.CNOT(wires=[0, 1])\n",
                "    qml.RY(weights[2], wires=0)\n",
                "    qml.RY(weights[3], wires=1)\n",
                "    return qml.expval(qml.PauliZ(0))\n",
                "\n",
                "weights_qgan = pnp.random.randn(4, requires_grad=True) * 0.1\n",
                "opt = qml.GradientDescentOptimizer(stepsize=0.05)\n",
                "early_stop = EarlyStoppingQML(patience=cfg['patience'])\n",
                "\n",
                "X_train_gan = X_train_qml[:, :2]\n",
                "X_val_gan = X_val_qml[:, :2]\n",
                "X_test_gan = X_test_qml[:, :2]\n",
                "\n",
                "def qgan_cost(weights, X, y):\n",
                "    loss = 0.0\n",
                "    for x_i, y_i in zip(X, y):\n",
                "        pred = (qgan_discriminator(weights, x_i) + 1) / 2\n",
                "        loss += (pred - y_i) ** 2\n",
                "    return loss / len(X)\n",
                "\n",
                "train_losses, val_losses = [], []\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(cfg['max_epochs']):\n",
                "    weights_qgan, cost = opt.step_and_cost(lambda w: qgan_cost(w, X_train_gan[:50], y_train_qml[:50]), weights_qgan)\n",
                "    train_losses.append(float(cost))\n",
                "    \n",
                "    val_cost = float(qgan_cost(weights_qgan, X_val_gan[:20], y_val_qml[:20]))\n",
                "    val_losses.append(val_cost)\n",
                "    \n",
                "    if (epoch + 1) % 10 == 0:\n",
                "        print(f\"  Epoch {epoch+1}/{cfg['max_epochs']}, Train: {cost:.4f}, Val: {val_cost:.4f}\")\n",
                "    \n",
                "    if early_stop(val_cost, epoch + 1):\n",
                "        print(f\"  Early stopping at epoch {epoch+1}\")\n",
                "        break\n",
                "\n",
                "train_time = time.time() - start_time\n",
                "stopped_epoch = early_stop.stopped_epoch if early_stop.early_stop else epoch + 1\n",
                "\n",
                "y_prob_qgan = np.array([(float(qgan_discriminator(weights_qgan, x)) + 1) / 2 for x in X_test_gan])\n",
                "y_pred_qgan = (y_prob_qgan > 0.5).astype(int)\n",
                "\n",
                "metrics = compute_metrics(y_test_qml, y_pred_qgan, y_prob_qgan)\n",
                "metrics.update({'model': 'QGAN', 'n_qubits': n_qubits_gan, 'circuit_depth': 1,\n",
                "                'train_time': train_time, 'stopped_epoch': stopped_epoch})\n",
                "all_metrics.append(metrics)\n",
                "all_histories['QGAN'] = {'train': train_losses, 'val': val_losses}\n",
                "all_probabilities['QGAN'] = y_prob_qgan\n",
                "epoch_metadata['QGAN'] = {'max_epochs': cfg['max_epochs'], 'patience': cfg['patience'], 'stopped_epoch': stopped_epoch}\n",
                "print(f\"  F1: {metrics['f1_score']:.4f}, Stopped: {stopped_epoch}/{cfg['max_epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "metrics_df = pd.DataFrame(all_metrics)\n",
                "col_order = ['model', 'accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'fpr', 'tpr', \n",
                "             'n_qubits', 'circuit_depth', 'train_time', 'stopped_epoch']\n",
                "metrics_df = metrics_df[[c for c in col_order if c in metrics_df.columns]]\n",
                "\n",
                "metrics_path = RESULTS_DIR / 'qml_metrics.csv'\n",
                "metrics_df.to_csv(metrics_path, index=False)\n",
                "\n",
                "# Save epoch metadata\n",
                "with open(RESULTS_DIR / 'qml_epoch_metadata.json', 'w') as f:\n",
                "    json.dump(epoch_metadata, f, indent=2, default=str)\n",
                "\n",
                "print(f\"✅ Saved to: {metrics_path}\")\n",
                "print(\"\\nQML Results:\")\n",
                "print(metrics_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training curves (Train vs Val)\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, (name, history) in enumerate(all_histories.items()):\n",
                "    ax = axes[i]\n",
                "    ax.plot(history['train'], label='Train')\n",
                "    ax.plot(history['val'], label='Val')\n",
                "    meta = epoch_metadata[name]\n",
                "    if meta['stopped_epoch']:\n",
                "        ax.axvline(x=meta['stopped_epoch']-1, color='r', linestyle='--', alpha=0.5, label='Stopped')\n",
                "    ax.set_xlabel('Epoch')\n",
                "    ax.set_ylabel('Loss')\n",
                "    stopped = meta['stopped_epoch'] or meta['max_epochs']\n",
                "    ax.set_title(f\"{name} (stopped: {stopped}/{meta['max_epochs']})\")\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'qml_training_curves.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curves\n",
                "plt.figure(figsize=(10, 8))\n",
                "\n",
                "test_labels = {\n",
                "    'VQC': y_test_qml, 'Hybrid_QNN': y_test_qml, 'QSVM': y_test_qsvm,\n",
                "    'Quantum_Autoencoder': y_test_qml, 'QGAN': y_test_qml\n",
                "}\n",
                "\n",
                "for model_name, y_prob in all_probabilities.items():\n",
                "    if y_prob is not None and not np.any(np.isnan(y_prob)):\n",
                "        try:\n",
                "            y_true = test_labels[model_name]\n",
                "            fpr_vals, tpr_vals, _ = roc_curve(y_true, y_prob)\n",
                "            auc_val = metrics_df[metrics_df['model'] == model_name]['roc_auc'].values[0]\n",
                "            plt.plot(fpr_vals, tpr_vals, label=f'{model_name} (AUC={auc_val:.3f})')\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('ROC Curves - QML Models')\n",
                "plt.legend(loc='lower right')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'roc_curves_qml.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"QML MODELS SUMMARY (With Early Stopping)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Total models: {len(all_metrics)}\")\n",
                "print(f\"\\nBest by F1: {metrics_df.loc[metrics_df['f1_score'].idxmax(), 'model']} ({metrics_df['f1_score'].max():.4f})\")\n",
                "print(f\"Best by AUC: {metrics_df.loc[metrics_df['roc_auc'].idxmax(), 'model']} ({metrics_df['roc_auc'].max():.4f})\")\n",
                "print(\"\\nEpoch Summary:\")\n",
                "for name, meta in epoch_metadata.items():\n",
                "    if meta['stopped_epoch']:\n",
                "        print(f\"  {name}: {meta['stopped_epoch']}/{meta['max_epochs']} (patience={meta['patience']})\")\n",
                "    else:\n",
                "        print(f\"  {name}: N/A (kernel-based)\")\n",
                "print(\"\\n✅ Notebook 8 Complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}