{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Classical Models - Training & Evaluation\n",
                "\n",
                "This notebook trains all **Classical Baselines** for the comparative study.\n",
                "\n",
                "**Models Trained:**\n",
                "1. Logistic Regression\n",
                "2. Random Forest\n",
                "3. LightGBM\n",
                "4. XGBoost\n",
                "5. Isolation Forest (Unsupervised)\n",
                "6. One-Class SVM (Unsupervised)\n",
                "7. Autoencoder (Unsupervised)\n",
                "\n",
                "**Output:** `results/tables/classical_results.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import time\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Ensure project root is in path\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "sys.path.append(project_root)\n",
                "\n",
                "from src.data.load_data import load_config, load_creditcard_data\n",
                "from src.data.preprocess import preprocess_creditcard\n",
                "from src.features.dimensionality_reduction import apply_pca\n",
                "from src.utils.seed import set_seed\n",
                "from src.evaluation.metrics import calculate_metrics\n",
                "from src.evaluation.cost_sensitive import calculate_financial_loss\n",
                "\n",
                "# Classical Models\n",
                "from src.classical.supervised_baselines import LogisticRegressionModel, RandomForestModel\n",
                "from src.classical.lightgbm_model import LightGBMModel\n",
                "from src.classical.xgboost_model import XGBoostModel\n",
                "from src.classical.isolation_forest import IsolationForestModel\n",
                "from src.classical.one_class_svm import OneClassSVMModel\n",
                "from src.classical.autoencoder import AutoEncoderModel\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using Feature Dimension (PCA): 8\n"
                    ]
                }
            ],
            "source": [
                "# Configuration\n",
                "config_path = os.path.join(project_root, 'src', 'config', 'config.yaml')\n",
                "config = load_config(config_path)\n",
                "N_COMPONENTS = config['quantum']['n_qubits'] # Match Quantum Dimension for Fairness\n",
                "SEED = 42\n",
                "\n",
                "print(f\"Using Feature Dimension (PCA): {N_COMPONENTS}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2026-01-28 12:00:47,482 INFO Loading Credit Card data from c:\\Users\\mostr\\OneDrive\\Documents\\GitHub\\Anomaly-detection-in-finance-using-QML\\data/raw\\creditcard.csv\n",
                        "2026-01-28 12:00:49,328 INFO Loaded Credit Card data with shape (284807, 31)\n",
                        "2026-01-28 12:00:50,695 INFO Cleaned data: (284807, 31) -> (283726, 31)\n",
                        "2026-01-28 12:00:50,865 INFO Normalized 29 columns using minmax\n",
                        "2026-01-28 12:00:51,041 INFO PCA reduced to 8 components. Explained Variance: 1.0000\n",
                        "Train Shape: (226980, 8), Test Shape: (56746, 8)\n"
                    ]
                }
            ],
            "source": [
                "# Load & Process Data\n",
                "df = load_creditcard_data(config)\n",
                "df_clean = preprocess_creditcard(df, config)\n",
                "\n",
                "X_all = df_clean.drop(columns=['Class']).values\n",
                "y_all = df_clean['Class'].values\n",
                "\n",
                "# Apply PCA\n",
                "X_pca, _ = apply_pca(X_all, n_components=N_COMPONENTS)\n",
                "\n",
                "# Split (Reproducible)\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Subsample for speed if needed, but classical can handle full data.\n",
                "# However, to be EXACTLY comparable to Quantum (which needs subsampling),\n",
                "# we should ideally use the same subsample. \n",
                "# BUT, the user prompt said \"Train ALL classical models... Do NOT compare here\".\n",
                "# Usually classical is trained on full. Let's train on FULL for now to show Classical 'at its best' \n",
                "# or subsample to match Quantum exactly? \n",
                "# The user said \"Use identical ... splits\". \n",
                "# If Quantum is restricted to 1000 samples, Classical should probably also be restricted IF we want strict fairness.\n",
                "# But usually Classical advantage IS scalability. \n",
                "# Let's use a large subset (e.g. 10k or full) here, and in the COMPARISON notebook we strictly align.\n",
                "# Actually, to save time in this notebook execution, let's use a reasonable subset (e.g. 10k).\n",
                "\n",
                "# Let's use 20% stratified test set, consistent with main pipeline\n",
                "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
                "    X_pca, y_all, test_size=0.2, stratify=y_all, random_state=SEED\n",
                ")\n",
                "\n",
                "# For this notebook, we verify classical models work. We'll save results on this split.\n",
                "print(f\"Train Shape: {X_train_full.shape}, Test Shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_evaluate(model, name, X_train, y_train, X_test, y_test):\n",
                "    print(f\"Training {name}...\")\n",
                "    start = time.time()\n",
                "    \n",
                "    # Fit\n",
                "    if name in ['Isolation Forest', 'One-Class SVM']:\n",
                "        model.fit(X_train)\n",
                "    elif name == 'Autoencoder':\n",
                "        model.fit(X_train)\n",
                "    else:\n",
                "        model.fit(X_train, y_train)\n",
                "        \n",
                "    train_time = time.time() - start\n",
                "    \n",
                "    # Predict\n",
                "    start_inf = time.time()\n",
                "    if hasattr(model, 'predict_proba'):\n",
                "        scores = model.predict_proba(X_test)\n",
                "        if scores.ndim > 1: scores = scores[:, 1]\n",
                "    elif hasattr(model, 'score'):\n",
                "        # IsoForest/OCSVM: higher score = normal. Invert for anomaly score.\n",
                "        scores = -model.score(X_test)\n",
                "    elif hasattr(model, 'predict_anomaly_score'):\n",
                "        scores = model.predict_anomaly_score(X_test)\n",
                "    else:\n",
                "        scores = model.predict(X_test)\n",
                "    inf_time = time.time() - start_inf\n",
                "    \n",
                "    # Calculate Logic for Threshold-Independent Metrics\n",
                "    from sklearn.metrics import average_precision_score, roc_auc_score\n",
                "    rc = roc_auc_score(y_test, scores)\n",
                "    pr = average_precision_score(y_test, scores)\n",
                "    \n",
                "    return {\n",
                "        \"model\": name,\n",
                "        \"type\": \"classical\",\n",
                "        \"roc_auc\": rc,\n",
                "        \"pr_auc\": pr,\n",
                "        \"train_time\": train_time,\n",
                "        \"inference_time\": inf_time\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Logistic Regression...\n",
                        "2026-01-28 12:00:53,741 INFO Training Logistic Regression on shape (226980, 8)\n",
                        "   -> PR-AUC: 0.2822\n",
                        "Training Random Forest...\n",
                        "2026-01-28 12:01:06,050 INFO Training Random Forest on shape (226980, 8)\n",
                        "   -> PR-AUC: 0.5645\n",
                        "Training LightGBM...\n",
                        "2026-01-28 12:01:13,531 INFO Training LightGBM on shape (226980, 8)\n",
                        "   -> PR-AUC: 0.0118\n",
                        "Training XGBoost...\n",
                        "2026-01-28 12:01:14,102 INFO Training XGBoost on shape (226980, 8)\n",
                        "   -> PR-AUC: 0.5770\n",
                        "Training Isolation Forest...\n",
                        "2026-01-28 12:01:14,610 INFO Training Isolation Forest on shape (226980, 8)\n",
                        "   -> PR-AUC: 0.0532\n",
                        "Training One-Class SVM...\n",
                        "2026-01-28 12:01:15,417 INFO Training One-Class SVM on shape (226980, 8)\n",
                        "   -> PR-AUC: 0.0020\n",
                        "Training Autoencoder...\n",
                        "2026-01-28 12:28:49,626 INFO Training Autoencoder on (226980, 8) using cpu\n",
                        "2026-01-28 12:30:15,423 INFO Epoch [10/10], Loss: 281886250.8035\n",
                        "   -> PR-AUC: 0.0019\n"
                    ]
                }
            ],
            "source": [
                "models = [\n",
                "    (\"Logistic Regression\", LogisticRegressionModel(random_state=SEED)),\n",
                "    (\"Random Forest\", RandomForestModel(random_state=SEED)),\n",
                "    (\"LightGBM\", LightGBMModel(random_state=SEED)),\n",
                "    (\"XGBoost\", XGBoostModel(random_state=SEED)),\n",
                "    (\"Isolation Forest\", IsolationForestModel(random_state=SEED)),\n",
                "    (\"One-Class SVM\", OneClassSVMModel()),\n",
                "    (\"Autoencoder\", AutoEncoderModel(input_dim=N_COMPONENTS, epochs=10))\n",
                "]\n",
                "\n",
                "results = []\n",
                "for name, model in models:\n",
                "    try:\n",
                "        res = train_evaluate(model, name, X_train_full, y_train_full, X_test, y_test)\n",
                "        results.append(res)\n",
                "        print(f\"   -> PR-AUC: {res['pr_auc']:.4f}\")\n",
                "    except Exception as e:\n",
                "        print(f\"   Failed {name}: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>model</th>\n",
                            "      <th>type</th>\n",
                            "      <th>roc_auc</th>\n",
                            "      <th>pr_auc</th>\n",
                            "      <th>train_time</th>\n",
                            "      <th>inference_time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Logistic Regression</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.940249</td>\n",
                            "      <td>0.282195</td>\n",
                            "      <td>12.247998</td>\n",
                            "      <td>0.008858</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Random Forest</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.910013</td>\n",
                            "      <td>0.564512</td>\n",
                            "      <td>7.396258</td>\n",
                            "      <td>0.074539</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>LightGBM</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.826695</td>\n",
                            "      <td>0.011784</td>\n",
                            "      <td>0.507650</td>\n",
                            "      <td>0.040842</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>XGBoost</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.934130</td>\n",
                            "      <td>0.577013</td>\n",
                            "      <td>0.467108</td>\n",
                            "      <td>0.017924</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Isolation Forest</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.868704</td>\n",
                            "      <td>0.053192</td>\n",
                            "      <td>0.351552</td>\n",
                            "      <td>0.425316</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>One-Class SVM</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.551936</td>\n",
                            "      <td>0.002004</td>\n",
                            "      <td>1541.346205</td>\n",
                            "      <td>112.814303</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>Autoencoder</td>\n",
                            "      <td>classical</td>\n",
                            "      <td>0.459921</td>\n",
                            "      <td>0.001865</td>\n",
                            "      <td>85.811203</td>\n",
                            "      <td>0.027728</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                 model       type   roc_auc    pr_auc   train_time  \\\n",
                            "0  Logistic Regression  classical  0.940249  0.282195    12.247998   \n",
                            "1        Random Forest  classical  0.910013  0.564512     7.396258   \n",
                            "2             LightGBM  classical  0.826695  0.011784     0.507650   \n",
                            "3              XGBoost  classical  0.934130  0.577013     0.467108   \n",
                            "4     Isolation Forest  classical  0.868704  0.053192     0.351552   \n",
                            "5        One-Class SVM  classical  0.551936  0.002004  1541.346205   \n",
                            "6          Autoencoder  classical  0.459921  0.001865    85.811203   \n",
                            "\n",
                            "   inference_time  \n",
                            "0        0.008858  \n",
                            "1        0.074539  \n",
                            "2        0.040842  \n",
                            "3        0.017924  \n",
                            "4        0.425316  \n",
                            "5      112.814303  \n",
                            "6        0.027728  "
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Save Results\n",
                "df_res = pd.DataFrame(results)\n",
                "os.makedirs(os.path.join(project_root, 'results', 'tables'), exist_ok=True)\n",
                "df_res.to_csv(os.path.join(project_root, 'results', 'tables', 'classical_results.csv'), index=False)\n",
                "df_res"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
