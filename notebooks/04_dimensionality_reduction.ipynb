{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 4: Dimensionality Reduction (PCA)\n",
                "\n",
                "**Purpose**: Apply PCA/Kernel PCA to reduce features to ≤10 dimensions for QML compatibility.\n",
                "\n",
                "**Inputs**:\n",
                "- `feature_engineered_train.csv` from Notebook 3\n",
                "- `feature_engineered_test.csv` from Notebook 3\n",
                "\n",
                "**Outputs**:\n",
                "- `pca_train.csv` → `data/features/`\n",
                "- `pca_test.csv` → `data/features/`\n",
                "- `pca_model.pkl` → `models/`\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.decomposition import PCA, KernelPCA\n",
                "import joblib\n",
                "\n",
                "# Set random seed\n",
                "RANDOM_SEED = 42\n",
                "np.random.seed(RANDOM_SEED)\n",
                "\n",
                "# Paths\n",
                "BASE_DIR = Path('.').resolve().parent\n",
                "FEATURES_DIR = BASE_DIR / 'data' / 'features'\n",
                "MODELS_DIR = BASE_DIR / 'models'\n",
                "RESULTS_DIR = BASE_DIR / 'results'\n",
                "FIGURES_DIR = BASE_DIR / 'figures'\n",
                "\n",
                "# Configuration\n",
                "TARGET_COLUMN = 'Class'\n",
                "MAX_COMPONENTS = 10  # Maximum features for QML\n",
                "\n",
                "print(f\"Random Seed: {RANDOM_SEED}\")\n",
                "print(f\"Max Components: {MAX_COMPONENTS}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Feature-Engineered Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "train_df = pd.read_csv(FEATURES_DIR / 'feature_engineered_train.csv')\n",
                "test_df = pd.read_csv(FEATURES_DIR / 'feature_engineered_test.csv')\n",
                "\n",
                "print(f\"Training set: {train_df.shape}\")\n",
                "print(f\"Test set: {test_df.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate features and target\n",
                "X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
                "y_train = train_df[TARGET_COLUMN]\n",
                "\n",
                "X_test = test_df.drop(columns=[TARGET_COLUMN])\n",
                "y_test = test_df[TARGET_COLUMN]\n",
                "\n",
                "print(f\"Features before PCA: {X_train.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Variance Analysis (Full PCA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit full PCA to analyze variance explained\n",
                "pca_full = PCA(random_state=RANDOM_SEED)\n",
                "pca_full.fit(X_train)\n",
                "\n",
                "# Calculate cumulative variance explained\n",
                "explained_variance = pca_full.explained_variance_ratio_\n",
                "cumulative_variance = np.cumsum(explained_variance)\n",
                "\n",
                "print(f\"Total components: {len(explained_variance)}\")\n",
                "print(f\"\\nVariance explained by first {MAX_COMPONENTS} components: {cumulative_variance[MAX_COMPONENTS-1]*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize variance explained\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Individual variance\n",
                "n_show = min(20, len(explained_variance))\n",
                "axes[0].bar(range(1, n_show+1), explained_variance[:n_show], color='steelblue')\n",
                "axes[0].set_xlabel('Principal Component')\n",
                "axes[0].set_ylabel('Variance Explained Ratio')\n",
                "axes[0].set_title('Variance Explained by Component')\n",
                "axes[0].axvline(x=MAX_COMPONENTS, color='red', linestyle='--', label=f'n={MAX_COMPONENTS}')\n",
                "axes[0].legend()\n",
                "\n",
                "# Cumulative variance\n",
                "axes[1].plot(range(1, n_show+1), cumulative_variance[:n_show], 'bo-')\n",
                "axes[1].axhline(y=0.95, color='green', linestyle='--', label='95% variance')\n",
                "axes[1].axhline(y=0.99, color='orange', linestyle='--', label='99% variance')\n",
                "axes[1].axvline(x=MAX_COMPONENTS, color='red', linestyle='--', label=f'n={MAX_COMPONENTS}')\n",
                "axes[1].set_xlabel('Number of Components')\n",
                "axes[1].set_ylabel('Cumulative Variance Explained')\n",
                "axes[1].set_title('Cumulative Variance Explained')\n",
                "axes[1].legend()\n",
                "axes[1].set_ylim([0, 1.05])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'pca_variance_explained.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Optimal Component Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find minimum components for different variance thresholds\n",
                "thresholds = [0.90, 0.95, 0.99]\n",
                "\n",
                "print(\"Components needed for variance thresholds:\")\n",
                "for thresh in thresholds:\n",
                "    n_components = np.argmax(cumulative_variance >= thresh) + 1\n",
                "    print(f\"  {thresh*100:.0f}% variance: {n_components} components\")\n",
                "\n",
                "# We'll use MAX_COMPONENTS as our target\n",
                "n_components = MAX_COMPONENTS\n",
                "print(f\"\\n✅ Using {n_components} components (captures {cumulative_variance[n_components-1]*100:.2f}% variance)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Apply PCA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit PCA with selected number of components\n",
                "pca = PCA(n_components=n_components, random_state=RANDOM_SEED)\n",
                "\n",
                "# Fit on training data, transform both\n",
                "X_train_pca = pca.fit_transform(X_train)\n",
                "X_test_pca = pca.transform(X_test)\n",
                "\n",
                "# Create column names\n",
                "pca_columns = [f'PC{i+1}' for i in range(n_components)]\n",
                "\n",
                "# Convert to DataFrame\n",
                "X_train_pca_df = pd.DataFrame(X_train_pca, columns=pca_columns, index=X_train.index)\n",
                "X_test_pca_df = pd.DataFrame(X_test_pca, columns=pca_columns, index=X_test.index)\n",
                "\n",
                "print(f\"Training PCA shape: {X_train_pca_df.shape}\")\n",
                "print(f\"Test PCA shape: {X_test_pca_df.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display component statistics\n",
                "print(\"PCA Component Statistics (Training):\")\n",
                "print(X_train_pca_df.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Principal Components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2D scatter plot of first two components\n",
                "plt.figure(figsize=(10, 8))\n",
                "\n",
                "colors = ['#2ecc71', '#e74c3c']\n",
                "labels = ['Normal', 'Anomaly']\n",
                "\n",
                "for i, label in enumerate([0, 1]):\n",
                "    mask = y_train == label\n",
                "    plt.scatter(\n",
                "        X_train_pca_df.loc[mask, 'PC1'],\n",
                "        X_train_pca_df.loc[mask, 'PC2'],\n",
                "        c=colors[i],\n",
                "        label=labels[i],\n",
                "        alpha=0.6,\n",
                "        s=50\n",
                "    )\n",
                "\n",
                "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
                "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
                "plt.title('PCA: First Two Principal Components')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'pca_2d_scatter.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3D scatter plot\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "\n",
                "fig = plt.figure(figsize=(12, 9))\n",
                "ax = fig.add_subplot(111, projection='3d')\n",
                "\n",
                "for i, label in enumerate([0, 1]):\n",
                "    mask = y_train == label\n",
                "    ax.scatter(\n",
                "        X_train_pca_df.loc[mask, 'PC1'],\n",
                "        X_train_pca_df.loc[mask, 'PC2'],\n",
                "        X_train_pca_df.loc[mask, 'PC3'],\n",
                "        c=colors[i],\n",
                "        label=labels[i],\n",
                "        alpha=0.6,\n",
                "        s=50\n",
                "    )\n",
                "\n",
                "ax.set_xlabel('PC1')\n",
                "ax.set_ylabel('PC2')\n",
                "ax.set_zlabel('PC3')\n",
                "ax.set_title('PCA: First Three Principal Components')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'pca_3d_scatter.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Component distributions by class\n",
                "fig, axes = plt.subplots(2, 5, figsize=(16, 6))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, col in enumerate(pca_columns):\n",
                "    ax = axes[i]\n",
                "    for j, label in enumerate([0, 1]):\n",
                "        mask = y_train == label\n",
                "        ax.hist(\n",
                "            X_train_pca_df.loc[mask, col],\n",
                "            bins=30,\n",
                "            alpha=0.5,\n",
                "            color=colors[j],\n",
                "            label=labels[j]\n",
                "        )\n",
                "    ax.set_title(col)\n",
                "    ax.legend(fontsize=8)\n",
                "\n",
                "plt.suptitle('Component Distributions by Class', y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'pca_component_distributions.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Combine with target\n",
                "train_pca_final = X_train_pca_df.copy()\n",
                "train_pca_final[TARGET_COLUMN] = y_train.values\n",
                "\n",
                "test_pca_final = X_test_pca_df.copy()\n",
                "test_pca_final[TARGET_COLUMN] = y_test.values\n",
                "\n",
                "print(f\"Final training shape: {train_pca_final.shape}\")\n",
                "print(f\"Final test shape: {test_pca_final.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save PCA data\n",
                "train_path = FEATURES_DIR / 'pca_train.csv'\n",
                "test_path = FEATURES_DIR / 'pca_test.csv'\n",
                "\n",
                "train_pca_final.to_csv(train_path, index=False)\n",
                "test_pca_final.to_csv(test_path, index=False)\n",
                "\n",
                "print(f\"✅ Saved PCA training data to: {train_path}\")\n",
                "print(f\"✅ Saved PCA test data to: {test_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save PCA model\n",
                "pca_path = MODELS_DIR / 'pca_model.pkl'\n",
                "joblib.dump(pca, pca_path)\n",
                "print(f\"✅ Saved PCA model to: {pca_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save PCA metadata\n",
                "pca_metadata = {\n",
                "    \"random_seed\": RANDOM_SEED,\n",
                "    \"n_components\": n_components,\n",
                "    \"original_features\": X_train.shape[1],\n",
                "    \"variance_explained\": {\n",
                "        \"per_component\": [round(v, 4) for v in pca.explained_variance_ratio_],\n",
                "        \"cumulative\": round(sum(pca.explained_variance_ratio_), 4)\n",
                "    },\n",
                "    \"component_names\": pca_columns\n",
                "}\n",
                "\n",
                "with open(RESULTS_DIR / 'pca_metadata.json', 'w') as f:\n",
                "    json.dump(pca_metadata, f, indent=2)\n",
                "\n",
                "print(f\"✅ Saved PCA metadata\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Verification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify saved files\n",
                "train_verify = pd.read_csv(FEATURES_DIR / 'pca_train.csv')\n",
                "test_verify = pd.read_csv(FEATURES_DIR / 'pca_test.csv')\n",
                "pca_verify = joblib.load(MODELS_DIR / 'pca_model.pkl')\n",
                "\n",
                "print(\"Verification:\")\n",
                "print(f\"  Training shape: {train_verify.shape}\")\n",
                "print(f\"  Test shape: {test_verify.shape}\")\n",
                "print(f\"  PCA components: {pca_verify.n_components_}\")\n",
                "print(f\"  Features (excl. target): {len(train_verify.columns) - 1}\")\n",
                "print(f\"\\n✅ Notebook 4 Complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PCA SUMMARY\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Original features: {X_train.shape[1]}\")\n",
                "print(f\"Reduced features: {n_components}\")\n",
                "print(f\"Variance retained: {sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
                "print(f\"Dimensionality reduction: {(1 - n_components/X_train.shape[1])*100:.1f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}